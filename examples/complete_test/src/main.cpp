/**
 * @file main.cpp
 * @brief å®Œæ•´æµ‹è¯•é¡¹ç›®ä¸»ç¨‹åº
 * 
 * è¿™ä¸ªç¨‹åºæ˜¯ lua_binding_generator çš„ç»¼åˆæµ‹è¯•å¥—ä»¶ï¼ŒåŒ…å«ï¼š
 * 1. 15ä¸ªæ ¸å¿ƒå®çš„100%è¦†ç›–æµ‹è¯•
 * 2. è¿è¡Œæ—¶åº“é›†æˆæµ‹è¯•
 * 3. æ€§èƒ½åŸºå‡†æµ‹è¯•
 * 4. çƒ­åŠ è½½åŠŸèƒ½æµ‹è¯•
 * 5. é”™è¯¯å¤„ç†æµ‹è¯•
 * 6. å†…å­˜ç®¡ç†æµ‹è¯•
 */

#include <iostream>
#include <string>
#include <vector>
#include <memory>
#include <chrono>
#include <iomanip>

// åŒ…å«æµ‹è¯•å¤´æ–‡ä»¶
#include "../headers/macro_coverage.h"
#include "../headers/runtime_features.h"

// åŒ…å«ç”Ÿæˆçš„ç»‘å®š
#include "CompleteTestBindings_bindings.h"

using namespace test_coverage;
using namespace runtime_test;

// ================================
// æµ‹è¯•é…ç½®å’Œé€‰é¡¹
// ================================

struct TestConfig {
    bool run_macro_tests = true;
    bool run_runtime_tests = true;
    bool run_performance_tests = true;
    bool run_stress_tests = false;
    bool verbose_output = true;
    bool generate_report = true;
    std::string output_file = "../../build/test_report.txt";
    int performance_iterations = 10;  // é™ä½è¿­ä»£æ¬¡æ•°é¿å…é•¿æ—¶é—´ç­‰å¾…
    int stress_test_objects = 1000;
};

// ================================
// æµ‹è¯•è¾…åŠ©å‡½æ•°
// ================================

void printHeader(const std::string& title) {
    std::cout << "\n" << std::string(60, '=') << "\n";
    std::cout << "  " << title << "\n";
    std::cout << std::string(60, '=') << "\n\n";
}

void printSection(const std::string& section) {
    std::cout << "\n--- " << section << " ---\n";
}

void printResult(const std::string& test_name, bool passed, const std::string& details = "") {
    std::cout << "[" << (passed ? "PASS" : "FAIL") << "] " << test_name;
    if (!details.empty()) {
        std::cout << " - " << details;
    }
    std::cout << "\n";
}

void printProgress(int current, int total, const std::string& task) {
    double percentage = (double)current / total * 100.0;
    std::cout << "\rProgress: [" << std::fixed << std::setprecision(1) 
              << percentage << "%] " << task << std::flush;
}

// ================================
// å®è¦†ç›–æµ‹è¯•å‡½æ•°
// ================================

bool testBasicMacros() {
    printSection("åŸºç¡€å®æµ‹è¯•");
    
    bool all_passed = true;
    
    // æµ‹è¯•å¸¸é‡
    printResult("EXPORT_LUA_CONSTANT", 
                MAX_CONNECTIONS == 1000 && PI_VALUE > 3.14 && DEBUG_ENABLED == true,
                "Constants: MAX_CONNECTIONS=" + std::to_string(MAX_CONNECTIONS));
    
    // æµ‹è¯•å˜é‡
    global_counter = 42;
    printResult("EXPORT_LUA_VARIABLE", 
                global_counter == 42 && system_name == "MacroCoverageTest",
                "Variables: global_counter=" + std::to_string(global_counter));
    
    // æµ‹è¯•æšä¸¾
    TestStatus status = TestStatus::ACTIVE;
    TestPriority priority = TestPriority::HIGH;
    printResult("EXPORT_LUA_ENUM", 
                static_cast<int>(status) == 1 && static_cast<int>(priority) == 10,
                "Enums working correctly");
    
    return all_passed;
}

bool testFunctionExports() {
    printSection("å‡½æ•°å¯¼å‡ºæµ‹è¯•");
    
    bool all_passed = true;
    
    // æµ‹è¯•å…¨å±€å‡½æ•°
    int sum = add_numbers(10, 20);
    printResult("add_numbers", sum == 30, "10 + 20 = " + std::to_string(sum));
    
    std::string formatted = format_message("Hello, {}!", "World");
    printResult("format_message", formatted == "Hello, World!", 
                "Template formatting: " + formatted);
    
    auto sequence = generate_sequence(1, 10, 2);
    printResult("generate_sequence", sequence.size() == 5 && sequence[0] == 1,
                "Generated " + std::to_string(sequence.size()) + " numbers");
    
    // æµ‹è¯•é‡è½½å‡½æ•°
    double circle_area = calculate_area(5.0);
    double rect_area = calculate_area(4.0, 3.0);
    printResult("calculate_area (overloaded)", 
                circle_area > 78.0 && rect_area == 12.0,
                "Circle: " + std::to_string(circle_area) + ", Rectangle: " + std::to_string(rect_area));
    
    return all_passed;
}

bool testClassHierarchy() {
    printSection("ç±»å±‚æ¬¡ç»“æ„æµ‹è¯•");
    
    bool all_passed = true;
    
    // æµ‹è¯•ç»§æ‰¿å…³ç³»
    auto player = std::make_shared<TestPlayer>("Hero", 5);
    printResult("TestPlayer creation", player->getName() == "Hero" && player->getLevel() == 5,
                "Player: " + player->getName() + ", Level: " + std::to_string(player->getLevel()));
    
    // æµ‹è¯•æŠ½è±¡ç±»æ–¹æ³•
    player->setHealth(80.0);
    player->addExperience(150);
    // æ³¨æ„ï¼šaddExperienceè§¦å‘levelUpï¼Œå‡çº§æ—¶ä¼šæ»¡è¡€ï¼ˆ6çº§=150è¡€ï¼‰
    printResult("Player operations", 
                player->getHealth() == 150.0 && player->getLevel() == 6,
                "Health: " + std::to_string(player->getHealth()) + ", Level: " + std::to_string(player->getLevel()));
    
    // æµ‹è¯•å¤šæ€æ€§
    std::string type = player->getType();
    double score = player->getScore();
    printResult("Polymorphism", type == "Player" && score > 0,
                "Type: " + type + ", Score: " + std::to_string(score));
    
    // æµ‹è¯•ç®¡ç†å™¨ç±»
    TestManager manager;
    manager.addPlayer(player);
    printResult("TestManager", manager.getPlayerCount() == 1,
                "Player count: " + std::to_string(manager.getPlayerCount()));
    
    return all_passed;
}

bool testStaticClasses() {
    printSection("é™æ€ç±»æµ‹è¯•");
    
    bool all_passed = true;
    
    // æµ‹è¯•æ•°å­¦å·¥å…·
    double clamped = TestMathUtils::clamp(15.0, 0.0, 10.0);
    double lerped = TestMathUtils::lerp(0.0, 100.0, 0.5);
    bool is_prime = TestMathUtils::isPrime(17);
    
    printResult("TestMathUtils", 
                clamped == 10.0 && lerped == 50.0 && is_prime,
                "clamp: " + std::to_string(clamped) + ", lerp: " + std::to_string(lerped));
    
    // æµ‹è¯•å­—ç¬¦ä¸²å·¥å…·
    std::string upper = TestStringUtils::toUpper("hello");
    std::string reversed = TestStringUtils::reverse("world");
    auto parts = TestStringUtils::split("a,b,c", ',');
    
    printResult("TestStringUtils", 
                upper == "HELLO" && reversed == "dlrow" && parts.size() == 3,
                "upper: " + upper + ", reverse: " + reversed + ", parts: " + std::to_string(parts.size()));
    
    return all_passed;
}

bool testSingletonPattern() {
    printSection("å•ä¾‹æ¨¡å¼æµ‹è¯•");
    
    bool all_passed = true;
    
    // æµ‹è¯•æ¸¸æˆç®¡ç†å™¨å•ä¾‹
    auto& game_mgr = TestGameManager::getInstance();
    game_mgr.startGame();
    game_mgr.addScore(100);
    
    // éªŒè¯å•ä¾‹ç‰¹æ€§
    auto& game_mgr2 = TestGameManager::getInstance();
    printResult("Singleton pattern", 
                &game_mgr == &game_mgr2 && game_mgr.getScore() == 100,
                "Same instance, Score: " + std::to_string(game_mgr.getScore()));
    
    return all_passed;
}

bool testOperatorOverloading() {
    printSection("è¿ç®—ç¬¦é‡è½½æµ‹è¯•");
    
    bool all_passed = true;
    
    // æµ‹è¯•å‘é‡è¿ç®—
    TestVector2D v1(3.0, 4.0);
    TestVector2D v2(1.0, 2.0);
    
    TestVector2D v3 = v1 + v2;
    TestVector2D v4 = v1 - v2;
    TestVector2D v5 = v1 * 2.0;
    
    printResult("Vector addition", v3.getX() == 4.0 && v3.getY() == 6.0,
                "(" + std::to_string(v3.getX()) + ", " + std::to_string(v3.getY()) + ")");
    
    printResult("Vector operations", 
                v4.getX() == 2.0 && v5.getX() == 6.0,
                "Subtraction and multiplication working");
    
    // æµ‹è¯•æ¯”è¾ƒè¿ç®—ç¬¦
    bool equal = (v1 == v1);
    bool not_equal = (v1 != v2);
    printResult("Comparison operators", equal && not_equal,
                "Equality and inequality working");
    
    return all_passed;
}

bool testCallbackSystem() {
    printSection("å›è°ƒç³»ç»Ÿæµ‹è¯•");
    
    bool all_passed = true;
    
    // æµ‹è¯•äº‹ä»¶ç³»ç»Ÿ
    TestEventSystem event_system;
    
    bool game_started = false;
    int score_changed = 0;
    
    event_system.OnGameStart = [&game_started]() {
        game_started = true;
    };
    
    event_system.OnScoreChange = [&score_changed](int new_score) {
        score_changed = new_score;
    };
    
    event_system.triggerGameStart();
    event_system.triggerScoreChange(150);
    
    printResult("Callback functions", 
                game_started && score_changed == 150,
                "Game started: " + std::string(game_started ? "true" : "false") + 
                ", Score: " + std::to_string(score_changed));
    
    return all_passed;
}

bool testContainerExports() {
    printSection("å®¹å™¨å¯¼å‡ºæµ‹è¯•");
    
    bool all_passed = true;
    
    // æµ‹è¯•å®¹å™¨ç®¡ç†å™¨
    TestContainerManager container_mgr;
    
    // æµ‹è¯•å‘é‡æ“ä½œ
    container_mgr.addNumber(10);
    container_mgr.addNumber(20);
    container_mgr.addNumber(30);
    
    auto numbers = container_mgr.getNumbers();
    printResult("Vector operations", 
                numbers.size() == 3 && numbers[1] == 20,
                "Vector size: " + std::to_string(numbers.size()));
    
    // æµ‹è¯•æ˜ å°„æ“ä½œ
    container_mgr.setProperty("name", "TestProject");
    container_mgr.setProperty("version", "2.0.0");
    
    std::string name = container_mgr.getProperty("name");
    printResult("Map operations", 
                name == "TestProject",
                "Property name: " + name);
    
    return all_passed;
}

// ================================
// è¿è¡Œæ—¶é›†æˆæµ‹è¯•å‡½æ•°
// ================================

bool testRuntimeInitialization() {
    printSection("è¿è¡Œæ—¶åˆå§‹åŒ–æµ‹è¯•");
    
    bool all_passed = true;
    
    RuntimeTestHelper runtime_helper;
    printResult("Runtime initialization", runtime_helper.initializeRuntime(),
                "Runtime manager created");
    
    // æµ‹è¯•è‡ªå®šä¹‰åˆ†é…å™¨
    auto tracking_allocator = std::make_shared<TestTrackingAllocator>();
    RuntimeTestHelper custom_runtime;
    bool custom_init = custom_runtime.initializeWithAllocator(tracking_allocator);
    printResult("Custom allocator", custom_init,
                "Runtime with tracking allocator");
    
    return all_passed;
}

bool testMemoryAllocators() {
    printSection("å†…å­˜åˆ†é…å™¨æµ‹è¯•");
    
    bool all_passed = true;
    
    // æµ‹è¯•è·Ÿè¸ªåˆ†é…å™¨
    auto tracking_alloc = std::make_shared<TestTrackingAllocator>();
    
    void* ptr1 = tracking_alloc->allocate(1024);
    void* ptr2 = tracking_alloc->allocate(2048);
    
    size_t total_before = tracking_alloc->getTotalAllocated();
    
    tracking_alloc->deallocate(ptr1, 1024);
    tracking_alloc->deallocate(ptr2, 2048);
    
    size_t total_after = tracking_alloc->getTotalAllocated();
    
    printResult("Tracking allocator", 
                total_before > 0 && total_after == 0 && !tracking_alloc->hasMemoryLeaks(),
                "Before: " + std::to_string(total_before) + ", After: " + std::to_string(total_after));
    
    // æµ‹è¯•å†…å­˜æ± åˆ†é…å™¨
    TestPoolAllocator pool_alloc(64 * 1024, 64);
    
    void* pool_ptr1 = pool_alloc.allocate(64);
    void* pool_ptr2 = pool_alloc.allocate(64);
    
    size_t used_blocks = pool_alloc.getUsedBlocks();
    
    pool_alloc.deallocate(pool_ptr1, 64);
    pool_alloc.deallocate(pool_ptr2, 64);
    
    size_t final_used = pool_alloc.getUsedBlocks();
    
    printResult("Pool allocator", 
                used_blocks == 2 && final_used == 0,
                "Used blocks: " + std::to_string(used_blocks) + " -> " + std::to_string(final_used));
    
    return all_passed;
}

bool testHotReloadSystem() {
    printSection("çƒ­åŠ è½½ç³»ç»Ÿæµ‹è¯•");
    
    bool all_passed = true;
    
    HotReloadTester hotreload_tester;
    
    // åˆå§‹åŒ–çƒ­é‡è½½æµ‹è¯•å™¨çš„è¿è¡Œæ—¶
    auto hotreload_runtime = std::make_shared<LuaRuntimeManager>();
    hotreload_tester.initialize(hotreload_runtime);
    
    bool basic_test = hotreload_tester.testBasicReload();
    bool protected_test = hotreload_tester.testProtectedTableReload();
    bool error_recovery = hotreload_tester.testErrorRecovery();
    
    printResult("Basic hot reload", basic_test, "Script reload completed");
    printResult("Protected table reload", protected_test, "State preservation working");
    printResult("Error recovery", error_recovery, "Error handling working");
    
    int successful = hotreload_tester.getSuccessfulReloads();
    int failed = hotreload_tester.getFailedReloads();
    
    printResult("Hot reload summary", successful > 0,
                "Successful: " + std::to_string(successful) + ", Failed: " + std::to_string(failed));
    
    return all_passed && basic_test && protected_test && error_recovery;
}

bool testErrorHandling() {
    printSection("é”™è¯¯å¤„ç†æµ‹è¯•");
    
    bool all_passed = true;
    
    ErrorHandlingTester error_tester;
    
    // åˆå§‹åŒ–é”™è¯¯å¤„ç†æµ‹è¯•å™¨çš„è¿è¡Œæ—¶
    error_tester.initializeRuntime();
    
    bool success_test = error_tester.testSuccessResult();
    bool error_test = error_tester.testErrorResult();
    bool recovery_test = error_tester.testErrorRecovery();
    
    printResult("Success result", success_test, "Success path working");
    printResult("Error result", error_test, "Error generation working");
    printResult("Error recovery", recovery_test, "Recovery mechanism working");
    
    int error_count = error_tester.getErrorCount();
    auto error_history = error_tester.getErrorHistory();
    
    // é”™è¯¯è·Ÿè¸ªæµ‹è¯•åº”è¯¥éªŒè¯ç³»ç»Ÿèƒ½å¤Ÿè®°å½•å†å²ï¼Œè€Œä¸æ˜¯ä¸€å®šè¦æœ‰é”™è¯¯
    printResult("Error tracking", !error_history.empty(),
                "Tracked " + std::to_string(error_count) + " errors");
    
    return all_passed && success_test && error_test && recovery_test;
}

// ================================
// æ€§èƒ½æµ‹è¯•å‡½æ•°
// ================================

bool runLuaBindingTests(const TestConfig& config) {
    printSection("Lua ç»‘å®šåŠŸèƒ½æµ‹è¯•");
    
    bool all_passed = true;
    
    // åˆ›å»ºè¿è¡Œæ—¶ç®¡ç†å™¨
    std::unique_ptr<LuaRuntimeManager> runtime;
    try {
        std::cout << "ğŸ”§ åˆå§‹åŒ– Lua è¿è¡Œæ—¶..." << std::endl;
        runtime = std::make_unique<LuaRuntimeManager>();
        std::cout << "âœ… Lua è¿è¡Œæ—¶åˆå§‹åŒ–æˆåŠŸ" << std::endl;
        
        // æ³¨å†Œç”Ÿæˆçš„ç»‘å®š
        std::cout << "ğŸ”§ æ³¨å†Œ C++ ç»‘å®šåˆ° Lua..." << std::endl;
        register_CompleteTestBindings_bindings(runtime->getLuaState());
        std::cout << "âœ… ç»‘å®šæ³¨å†ŒæˆåŠŸ" << std::endl;
        
    } catch (const std::exception& e) {
        printResult("Runtime initialization", false, "Failed: " + std::string(e.what()));
        return false;
    }
    
    // è¿è¡Œä¸»æµ‹è¯•è„šæœ¬
    std::cout << "ğŸ” è¿è¡Œ Lua ç»‘å®šåŠŸèƒ½æµ‹è¯•..." << std::endl;
    auto script_result = runtime->executeFile("./lua_scripts/main_test.lua");
    
    if (script_result.isError()) {
        std::cout << "âŒ Lua è„šæœ¬æ‰§è¡Œå¤±è´¥" << std::endl;
        std::cout << "   é”™è¯¯: " << script_result.error().message << std::endl;
        printResult("Lua script execution", false, script_result.error().message);
        all_passed = false;
    } else {
        std::cout << "âœ… Lua è„šæœ¬æ‰§è¡Œå®Œæˆ" << std::endl;
        
        // æ£€æŸ¥è„šæœ¬è¿”å›å€¼
        try {
            bool script_success = script_result.value().as<bool>();
            printResult("Lua binding tests", script_success, 
                       script_success ? "All tests passed" : "Some tests failed");
            all_passed = script_success;
        } catch (...) {
            printResult("Lua binding tests", true, "Script executed successfully");
        }
    }
    
    return all_passed;
}

bool runPerformanceTests(const TestConfig& config) {
    printSection("æ€§èƒ½åŸºå‡†æµ‹è¯•");
    
    bool all_passed = true;
    
    PerformanceTester perf_tester;
    
    // åˆå§‹åŒ–è¿è¡Œæ—¶
    std::cout << "ğŸ”§ åˆå§‹åŒ–æ€§èƒ½æµ‹è¯•è¿è¡Œæ—¶..." << std::endl;
    if (!perf_tester.initializeRuntime()) {
        printResult("Performance test initialization", false, "Failed to initialize runtime");
        return false;
    }
    std::cout << "âœ… è¿è¡Œæ—¶åˆå§‹åŒ–æˆåŠŸ" << std::endl;
    
    // æ³¨å†Œç»‘å®šåˆ°æ€§èƒ½æµ‹è¯•è¿è¡Œæ—¶
    try {
        std::cout << "ğŸ”§ æ³¨å†Œç»‘å®šåˆ°æ€§èƒ½æµ‹è¯•è¿è¡Œæ—¶..." << std::endl;
        register_CompleteTestBindings_bindings(perf_tester.getRuntime().getLuaState());
        std::cout << "âœ… æ€§èƒ½æµ‹è¯•ç»‘å®šæ³¨å†ŒæˆåŠŸ" << std::endl;
    } catch (const std::exception& e) {
        printResult("Performance binding registration", false, e.what());
        return false;
    }
    
    // è„šæœ¬æ‰§è¡Œæ€§èƒ½ - ç°åœ¨ä½¿ç”¨çœŸå®çš„ Lua ç»‘å®šæµ‹è¯•
    std::cout << "ğŸ” å¼€å§‹ç»‘å®šè„šæœ¬æ€§èƒ½æµ‹è¯•..." << std::endl;
    double script_time = perf_tester.benchmarkScriptExecution(
        "local player = test_coverage.TestPlayer('PerfTest', 5); return player:getLevel()", 
        config.performance_iterations);
    std::cout << "âœ… ç»‘å®šè„šæœ¬æµ‹è¯•å®Œæˆ" << std::endl;
    printResult("Binding script execution", script_time >= 0.0,
                "Average: " + std::to_string(script_time) + " ms");
    
    // å‡½æ•°è°ƒç”¨æ€§èƒ½ - æµ‹è¯• C++ å‡½æ•°è°ƒç”¨
    std::cout << "ğŸ” å¼€å§‹ C++ å‡½æ•°è°ƒç”¨æ€§èƒ½æµ‹è¯•..." << std::endl;
    double func_time = perf_tester.benchmarkScriptExecution(
        "return test_coverage.add_numbers(10, 20)", 
        config.performance_iterations);
    std::cout << "âœ… C++ å‡½æ•°è°ƒç”¨æµ‹è¯•å®Œæˆ" << std::endl;
    printResult("C++ function calls", func_time >= 0.0,
                "Average: " + std::to_string(func_time) + " ms per call");
    
    // å¯¹è±¡åˆ›å»ºæ€§èƒ½ - æµ‹è¯• C++ å¯¹è±¡åˆ›å»º
    std::cout << "ğŸ” å¼€å§‹ C++ å¯¹è±¡åˆ›å»ºæ€§èƒ½æµ‹è¯•..." << std::endl;
    double obj_time = perf_tester.benchmarkScriptExecution(
        "for i=1,100 do local p = test_coverage.TestPlayer('Test'..i, i) end", 
        config.performance_iterations / 10);  // å‡å°‘è¿­ä»£ï¼Œå› ä¸ºåˆ›å»º100ä¸ªå¯¹è±¡è¾ƒæ…¢
    std::cout << "âœ… C++ å¯¹è±¡åˆ›å»ºæµ‹è¯•å®Œæˆ" << std::endl;
    printResult("C++ object creation", obj_time >= 0.0,
                "Average: " + std::to_string(obj_time) + " ms for 100 objects");
    
    // å‘é‡è¿ç®—æ€§èƒ½
    std::cout << "ğŸ” å¼€å§‹å‘é‡è¿ç®—æ€§èƒ½æµ‹è¯•..." << std::endl;
    double vector_time = perf_tester.benchmarkScriptExecution(
        "local v1 = test_coverage.TestVector2D(3, 4); local v2 = test_coverage.TestVector2D(1, 2); local v3 = v1 + v2; return v3:length()", 
        config.performance_iterations);
    std::cout << "âœ… å‘é‡è¿ç®—æµ‹è¯•å®Œæˆ" << std::endl;
    printResult("Vector operations", vector_time >= 0.0,
                "Average: " + std::to_string(vector_time) + " ms");
    
    if (config.verbose_output) {
        std::cout << "\n" << perf_tester.getPerformanceReport() << "\n";
    }
    
    return all_passed;
}

bool runStressTests(const TestConfig& config) {
    printSection("å‹åŠ›æµ‹è¯•");
    
    bool all_passed = true;
    
    RuntimeTestHelper runtime_helper;
    if (!runtime_helper.initializeRuntime()) {
        printResult("Stress test initialization", false, "Failed to initialize runtime");
        return false;
    }
    
    // å¯¹è±¡åˆ›å»ºå‹åŠ›æµ‹è¯•
    bool obj_stress = runtime_helper.runStressTest(config.stress_test_objects, 10);
    printResult("Object stress test", obj_stress,
                std::to_string(config.stress_test_objects * 10) + " objects created");
    
    // å†…å­˜å‹åŠ›æµ‹è¯•
    bool mem_stress = runtime_helper.runMemoryStressTest(50 * 1024 * 1024);
    printResult("Memory stress test", mem_stress, "50MB allocation test");
    
    // å¹¶å‘æµ‹è¯•
    bool concurrency_test = runtime_helper.runConcurrencyTest(4);
    printResult("Concurrency test", concurrency_test, "4 concurrent threads");
    
    return all_passed && obj_stress && mem_stress && concurrency_test;
}

// ================================
// é›†æˆæµ‹è¯•åè°ƒå™¨
// ================================

bool runIntegratedTestSuite(const TestConfig& config) {
    printSection("é›†æˆæµ‹è¯•å¥—ä»¶");
    
    auto& coordinator = IntegrationTestCoordinator::getInstance();
    
    if (!coordinator.initializeTestSuite()) {
        printResult("Test suite initialization", false, "Failed to initialize");
        return false;
    }
    
    coordinator.setVerboseOutput(config.verbose_output);
    
    bool all_passed = true;
    
    if (config.run_macro_tests) {
        all_passed &= coordinator.runMacroTests();
    }
    
    if (config.run_runtime_tests) {
        all_passed &= coordinator.runRuntimeTests();
    }
    
    if (config.run_performance_tests) {
        all_passed &= coordinator.runPerformanceTests();
    }
    
    if (config.run_stress_tests) {
        all_passed &= coordinator.runStressTests();
    }
    
    // è·å–æµ‹è¯•æŠ¥å‘Š
    std::string report = coordinator.getTestReport();
    if (config.verbose_output) {
        std::cout << "\n" << report << "\n";
    }
    
    // å¯¼å‡ºæŠ¥å‘Š
    if (config.generate_report) {
        coordinator.exportTestResults(config.output_file);
        printResult("Report generation", true, "Report saved to " + config.output_file);
    }
    
    coordinator.shutdownTestSuite();
    
    return all_passed;
}

// ================================
// ä¸»ç¨‹åºå…¥å£
// ================================

void printUsage(const char* program_name) {
    std::cout << "Usage: " << program_name << " [options]\n\n";
    std::cout << "Options:\n";
    std::cout << "  --help, -h          Show this help message\n";
    std::cout << "  --macro-only        Run only macro coverage tests\n";
    std::cout << "  --runtime-only      Run only runtime integration tests\n";
    std::cout << "  --performance-only  Run only performance tests\n";
    std::cout << "  --stress            Include stress tests\n";
    std::cout << "  --quiet, -q         Quiet output (less verbose)\n";
    std::cout << "  --no-report         Don't generate test report file\n";
    std::cout << "  --output FILE       Output report to FILE (default: test_report.txt)\n";
    std::cout << "  --iterations N      Performance test iterations (default: 100)\n";
    std::cout << "  --objects N         Stress test object count (default: 1000)\n\n";
    std::cout << "Examples:\n";
    std::cout << "  " << program_name << "                  # Run all tests\n";
    std::cout << "  " << program_name << " --macro-only     # Test macro coverage only\n";
    std::cout << "  " << program_name << " --stress --quiet # Run stress tests quietly\n";
}

TestConfig parseArguments(int argc, char* argv[]) {
    TestConfig config;
    
    for (int i = 1; i < argc; ++i) {
        std::string arg = argv[i];
        
        if (arg == "--help" || arg == "-h") {
            printUsage(argv[0]);
            exit(0);
        } else if (arg == "--macro-only") {
            config.run_runtime_tests = false;
            config.run_performance_tests = false;
        } else if (arg == "--runtime-only") {
            config.run_macro_tests = false;
            config.run_performance_tests = false;
        } else if (arg == "--performance-only") {
            config.run_macro_tests = false;
            config.run_runtime_tests = false;
            config.run_performance_tests = true;
        } else if (arg == "--stress") {
            config.run_stress_tests = true;
        } else if (arg == "--quiet" || arg == "-q") {
            config.verbose_output = false;
        } else if (arg == "--no-report") {
            config.generate_report = false;
        } else if (arg == "--output" && i + 1 < argc) {
            config.output_file = argv[++i];
        } else if (arg == "--iterations" && i + 1 < argc) {
            config.performance_iterations = std::stoi(argv[++i]);
        } else if (arg == "--objects" && i + 1 < argc) {
            config.stress_test_objects = std::stoi(argv[++i]);
        }
    }
    
    return config;
}

int main(int argc, char* argv[]) {
    auto start_time = std::chrono::steady_clock::now();
    
    TestConfig config = parseArguments(argc, argv);
    
    printHeader("Lua Binding Generator - å®Œæ•´æµ‹è¯•å¥—ä»¶ v2.0.0");
    
    if (config.verbose_output) {
        std::cout << "æµ‹è¯•é…ç½®:\n";
        std::cout << "  å®è¦†ç›–æµ‹è¯•: " << (config.run_macro_tests ? "æ˜¯" : "å¦") << "\n";
        std::cout << "  è¿è¡Œæ—¶æµ‹è¯•: " << (config.run_runtime_tests ? "æ˜¯" : "å¦") << "\n";
        std::cout << "  æ€§èƒ½æµ‹è¯•: " << (config.run_performance_tests ? "æ˜¯" : "å¦") << "\n";
        std::cout << "  å‹åŠ›æµ‹è¯•: " << (config.run_stress_tests ? "æ˜¯" : "å¦") << "\n";
        std::cout << "  æ€§èƒ½è¿­ä»£æ¬¡æ•°: " << config.performance_iterations << "\n";
        std::cout << "  å‹åŠ›æµ‹è¯•å¯¹è±¡æ•°: " << config.stress_test_objects << "\n";
        std::cout << "  è¾“å‡ºæ–‡ä»¶: " << config.output_file << "\n\n";
    }
    
    bool all_tests_passed = true;
    int total_test_categories = 0;
    int passed_categories = 0;
    
    try {
        // è¿è¡Œå®è¦†ç›–æµ‹è¯•
        if (config.run_macro_tests) {
            printHeader("å®è¦†ç›–æµ‹è¯• (100% è¦†ç›– 15ä¸ªæ ¸å¿ƒå®)");
            
            bool macro_tests[] = {
                testBasicMacros(),
                testFunctionExports(),
                testClassHierarchy(),
                testStaticClasses(),
                testSingletonPattern(),
                testOperatorOverloading(),
                testCallbackSystem(),
                testContainerExports()
            };
            
            for (bool result : macro_tests) {
                total_test_categories++;
                if (result) passed_categories++;
                all_tests_passed &= result;
            }
        }
        
        // è¿è¡Œè¿è¡Œæ—¶é›†æˆæµ‹è¯•
        if (config.run_runtime_tests) {
            printHeader("è¿è¡Œæ—¶åº“é›†æˆæµ‹è¯•");
            
            bool runtime_tests[] = {
                testRuntimeInitialization(),
                testMemoryAllocators(),
                testHotReloadSystem(),
                testErrorHandling()
            };
            
            for (bool result : runtime_tests) {
                total_test_categories++;
                if (result) passed_categories++;
                all_tests_passed &= result;
            }
        }
        
        // è¿è¡Œ Lua ç»‘å®šåŠŸèƒ½æµ‹è¯•
        printHeader("Lua ç»‘å®šåŠŸèƒ½æµ‹è¯•");
        bool binding_result = runLuaBindingTests(config);
        total_test_categories++;
        if (binding_result) passed_categories++;
        all_tests_passed &= binding_result;
        
        // è¿è¡Œæ€§èƒ½æµ‹è¯•
        if (config.run_performance_tests) {
            printHeader("æ€§èƒ½åŸºå‡†æµ‹è¯•");
            bool perf_result = runPerformanceTests(config);
            total_test_categories++;
            if (perf_result) passed_categories++;
            all_tests_passed &= perf_result;
        }
        
        // è¿è¡Œå‹åŠ›æµ‹è¯•
        if (config.run_stress_tests) {
            printHeader("å‹åŠ›æµ‹è¯•");
            bool stress_result = runStressTests(config);
            total_test_categories++;
            if (stress_result) passed_categories++;
            all_tests_passed &= stress_result;
        }
        
        // è¿è¡Œé›†æˆæµ‹è¯•å¥—ä»¶
        printHeader("é›†æˆæµ‹è¯•åè°ƒå™¨");
        bool integration_result = runIntegratedTestSuite(config);
        total_test_categories++;
        if (integration_result) passed_categories++;
        all_tests_passed &= integration_result;
        
    } catch (const std::exception& e) {
        std::cerr << "\nè‡´å‘½é”™è¯¯: " << e.what() << "\n";
        all_tests_passed = false;
    }
    
    // è®¡ç®—æ€»æ—¶é—´
    auto end_time = std::chrono::steady_clock::now();
    double total_duration = std::chrono::duration<double>(end_time - start_time).count();
    
    // æ‰“å°æœ€ç»ˆç»“æœ
    printHeader("æµ‹è¯•ç»“æœæ‘˜è¦");
    
    std::cout << "æµ‹è¯•ç±»åˆ«: " << passed_categories << "/" << total_test_categories << " é€šè¿‡\n";
    std::cout << "æ€»ä½“ç»“æœ: " << (all_tests_passed ? "æˆåŠŸ" : "å¤±è´¥") << "\n";
    std::cout << "æ‰§è¡Œæ—¶é—´: " << std::fixed << std::setprecision(2) << total_duration << " ç§’\n";
    
    if (config.generate_report) {
        std::cout << "è¯¦ç»†æŠ¥å‘Š: " << config.output_file << "\n";
    }
    
    if (all_tests_passed) {
        std::cout << "\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼lua_binding_generator å·¥ä½œæ­£å¸¸ã€‚\n";
        std::cout << "âœ… 15ä¸ªæ ¸å¿ƒå®100%è¦†ç›–\n";
        std::cout << "âœ… è¿è¡Œæ—¶åº“é›†æˆæ­£å¸¸\n";
        std::cout << "âœ… æ€§èƒ½æ»¡è¶³è¦æ±‚\n";
        if (config.run_stress_tests) {
            std::cout << "âœ… å‹åŠ›æµ‹è¯•é€šè¿‡\n";
        }
    } else {
        std::cout << "\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°è¾“å‡ºäº†è§£è¯¦æƒ…ã€‚\n";
    }
    
    std::cout << "\n" << std::string(60, '=') << "\n";
    
    return all_tests_passed ? 0 : 1;
}